{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"brain-mri-segmentation.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNxLTmDtYa2aYYen4YULmAX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"juiJJNDjzTwV"},"source":["import os \n","import random\n","import pandas as pd \n","import numpy as np    \n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from tensorflow.python.keras.backend import concatenate\n","from tensorflow.python.keras.layers.convolutional import Conv2D, Conv2DTranspose\n","from tensorflow.python.keras.layers.core import Lambda\n","from tensorflow.python.keras.layers.pooling import MaxPool2D, MaxPooling2D\n","plt.style.use(\"ggplot\")\n","\n","import cv2\n","from tqdm import tnrange, tqdm_notebook\n","from glob import glob\n","from itertools import chain\n","from skimage.io import imread, imshow, concatenate_images\n","from skimage.transform import resize\n","from skimage.morphology import label\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","from skimage.color import rgb2gray\n","from tensorflow.keras import Input\n","from tensorflow.keras.models import Model, load_model, save_model\n","from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjOoBCIofkzr"},"source":["im_width = 256\n","im_height = 256"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ZCOCLuTXy2l"},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0CLdA5FUYB23"},"source":["path = '/content/gdrive/My Drive/Colab_Notebooks/Brain-MRI-Segmentation2/kaggle_3m'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iwVA5tPj12kq"},"source":["from numpy import savez\n","# save data in train_files \n","train_files = []\n","mask_files = glob('/content/gdrive/My Drive/Colab_Notebooks/Brain-MRI-Segmentation2/kaggle_3m/*/*_mask*')\n","\n","for i in mask_files:\n","    train_files.append(i.replace('_mask',''))\n","# print(train_files[:10])\n","# print(mask_files[:10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzmDCtkAfj0r"},"source":["#Lets plot some samples\n","rows,cols=3,3\n","fig=plt.figure(figsize=(10,10))\n","for i in range(1,rows*cols+1):\n","    fig.add_subplot(rows,cols,i)\n","    img_path=train_files[i]\n","    msk_path=mask_files[i]\n","    img=cv2.imread(img_path)\n","    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","    msk=cv2.imread(msk_path)\n","    plt.imshow(img)\n","    plt.imshow(msk,alpha=0.4)\n","plt.show()  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TzEP-VleXx-3"},"source":["#Share data trainn/test/val\n","df = pd.DataFrame(data={\"filename\": train_files, 'mask' : mask_files})\n","df_train, df_test = train_test_split(df,test_size = 0.1)\n","df_train, df_val = train_test_split(df_train,test_size = 0.2)\n","print(df_train.values.shape)\n","print(df_val.values.shape)\n","print(df_test.values.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iIo0RSRAleyd"},"source":["def train_generator(data_frame, batch_size, aug_dict,\n","        image_color_mode=\"rgb\",\n","        mask_color_mode=\"grayscale\",\n","        image_save_prefix=\"image\",\n","        mask_save_prefix=\"mask\",\n","        save_to_dir=None,\n","        target_size=(256,256),\n","        seed=1):\n","    image_datagen = ImageDataGenerator(**aug_dict)\n","    mask_datagen = ImageDataGenerator(**aug_dict)\n","    \n","    image_generator = image_datagen.flow_from_dataframe(\n","        data_frame,\n","        x_col = \"filename\",\n","        class_mode = None,\n","        color_mode = image_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = image_save_prefix,\n","        seed = seed)\n","\n","    mask_generator = mask_datagen.flow_from_dataframe(\n","        data_frame,\n","        x_col = \"mask\",\n","        class_mode = None,\n","        color_mode = mask_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = mask_save_prefix,\n","        seed = seed)\n","\n","    train_gen = zip(image_generator, mask_generator)\n","    \n","    for (img, mask) in train_gen:\n","        img, mask = adjust_data(img, mask)\n","        yield (img,mask)\n","\n","def adjust_data(img,mask):\n","    img = img / 255\n","    mask = mask / 255\n","    mask[mask > 0.5] = 1\n","    mask[mask <= 0.5] = 0\n","    \n","    return (img, mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8WW6E29E12tg"},"source":["#Get IoU\n","smooth=100\n","\n","def dice_coef(y_true, y_pred):\n","    y_truef=K.flatten(y_true)\n","    y_predf=K.flatten(y_pred)\n","    And=K.sum(y_truef* y_predf)\n","    return((2* And + smooth) / (K.sum(y_truef) + K.sum(y_predf) + smooth))\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)\n","\n","def iou(y_true, y_pred):\n","    intersection = K.sum(y_true * y_pred)\n","    sum_ = K.sum(y_true + y_pred)\n","    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n","    return jac\n","\n","def jac_distance(y_true, y_pred):\n","    y_truef=K.flatten(y_true)\n","    y_predf=K.flatten(y_pred)\n","\n","    return - iou(y_true, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9uJcsQ5nTrc"},"source":["def unet(input_size=(256,256,3)):\n","    inputs = Input(input_size)\n","    \n","    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n","    bn1 = Activation('relu')(conv1)\n","    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n","    bn1 = BatchNormalization(axis=3)(conv1)\n","    bn1 = Activation('relu')(bn1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n","\n","    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n","    bn2 = Activation('relu')(conv2)\n","    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n","    bn2 = BatchNormalization(axis=3)(conv2)\n","    bn2 = Activation('relu')(bn2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n","\n","    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n","    bn3 = Activation('relu')(conv3)\n","    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n","    bn3 = BatchNormalization(axis=3)(conv3)\n","    bn3 = Activation('relu')(bn3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n","\n","    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n","    bn4 = Activation('relu')(conv4)\n","    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n","    bn4 = BatchNormalization(axis=3)(conv4)\n","    bn4 = Activation('relu')(bn4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n","\n","    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)\n","    bn5 = Activation('relu')(conv5)\n","    conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)\n","    bn5 = BatchNormalization(axis=3)(conv5)\n","    bn5 = Activation('relu')(bn5)\n","\n","    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n","    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n","    bn6 = Activation('relu')(conv6)\n","    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)\n","    bn6 = BatchNormalization(axis=3)(conv6)\n","    bn6 = Activation('relu')(bn6)\n","\n","    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n","    conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n","    bn7 = Activation('relu')(conv7)\n","    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n","    bn7 = BatchNormalization(axis=3)(conv7)\n","    bn7 = Activation('relu')(bn7)\n","\n","    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n","    conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n","    bn8 = Activation('relu')(conv8)\n","    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n","    bn8 = BatchNormalization(axis=3)(conv8)\n","    bn8 = Activation('relu')(bn8)\n","\n","    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n","    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n","    bn9 = Activation('relu')(conv9)\n","    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n","    bn9 = BatchNormalization(axis=3)(conv9)\n","    bn9 = Activation('relu')(bn9)\n","\n","    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n","\n","    return Model(inputs=[inputs], outputs=[conv10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jWPGrI3Ul3Av"},"source":["model = unet()\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PiGOt0lVl3ht"},"source":["#Set epochs\n","EPOCHS = 20\n","BATCH_SIZE = 32\n","learning_rate = 1e-4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhklIyyGmBYL"},"source":["#train model\n","train_generator_args = dict(rotation_range=0.2,\n","                            width_shift_range=0.05,\n","                            height_shift_range=0.05,\n","                            shear_range=0.05,\n","                            zoom_range=0.05,\n","                            horizontal_flip=True,\n","                            fill_mode='nearest')\n","train_gen = train_generator(df_train, BATCH_SIZE,\n","                                train_generator_args,\n","                                target_size=(im_height, im_width))\n","    \n","test_gener = train_generator(df_val, BATCH_SIZE,\n","                                dict(),\n","                                target_size=(im_height, im_width))\n","    \n","model = unet(input_size=(im_height, im_width, 3))\n","\n","\n","\n","decay_rate = learning_rate / EPOCHS\n","opt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\n","model.compile(optimizer=opt, loss=dice_coef_loss, metrics=[\"binary_accuracy\", iou, dice_coef])\n","\n","callbacks = [ModelCheckpoint('unet_brain_mri_seg.hdf5', verbose=1, save_best_only=True)]\n","\n","history = model.fit(train_gen,\n","                    steps_per_epoch=len(df_train) / BATCH_SIZE, \n","                    epochs=EPOCHS, \n","                    callbacks=callbacks,\n","                    validation_data = test_gener,\n","                    validation_steps=len(df_val) / BATCH_SIZE)"],"execution_count":null,"outputs":[]}]}